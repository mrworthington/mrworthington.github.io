---
title: "Analyzing COVID-19 in Austin"
description: |
  Austin has been profiled numerous times throughout the pandemic as being relentless in its efforts to get good COVID-19 data, despite multiple challenges and barriers. This is the first in a set of posts where I take a look at local COVID-19 data for Austin and explore themes of risk, resilience, and disparities as it pertains to COVID-19 in Austin.
author:
  - name: Matt Worthington 
    url: https://mrworthington.com/about
    affiliation: Me, Myself, and I
    affiliation_url: https://mrworthington.com
date: 08-13-2020
creative_commons: CC BY-NC
output:
  distill::distill_article:
    css: hospital_header.css
    self_contained: false
preview: ryan-magsino-sohLeI-k-HU-unsplash.jpg
categories:
  - COVID19
  - Public Health
  - Austin Public Health
  - I35
  - Austin
  - Public Data
twitter:
  creator: "@mrworthington"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(flextable)
library(geojson)
library(geojsonsf)
library(gfonts)
library(gghighlight)
library(gt)
library(highcharter)
library(janitor)
library(Knoema)
library(lubridate)
library(patchwork)
library(png)
library(rcartocolor)
library(readxl)
library(RSocrata)
library(sf)
library(tidycensus)
library(tidyverse)
library(tigris)
library(tinter)
library(tmap)
library(tmaptools)
library(vroom)
readRenviron("~/.Renviron")
census_api_key <- Sys.getenv("CENSUS_API_KEY")
census_api_key(key=census_api_key)
options(tigris_use_cache=TRUE)
```

Approaching the six-month mark of COVID-19 in Texas, one of the more common topics of discussion I hear is what the effects of coronavirus on our communities reveals about the world that existed before. And where we knew little about COVID-19 back in March, since that time a lot has been documented about what increases the risk of not only becoming severely ill, but also what increases the risk of being exposed to COVID-19 before you even get sick---such as having a job that requires you to be physically present for work (as opposed to working remotely from home) or not having access to a reliable internet connection. 

That said, I want to explore some of these things in a series of blog posts--to see who is not only getting COVID, but also *where* folks are most at risk of being exposed to COVID and where they're most at risk of not bouncing back. The trouble in answering these questions is that getting good data is difficult and, once you have it, organizing the data in a way that is useful and meaningful for others is even harder. So, I'm going to pace myself and search for datasets that can inform our conversation. For the purposes of these blog posts, I'm just going to focus on looking at the city-wide data in Austin---where I live---because I know all the data exists with regards to the questions I have pulled together. If you have questions, I invite you to ask them as well and I'll do my best to find data that can help provided some meaningful insight.
 
<aside>

The Texas Tribune had [a good write-up on the caveats of state-wide data](https://www.texastribune.org/2020/08/04/texas-coronavirus-data/) that I' would recommend reading on this topic.  
</aside>

## Who is getting COVID-19 in Austin?

Before we do any exploration of the more complicated questions identified, the best starting point would be exploring where COVID is occuring most in Austin. So let's look at that before digging into other questions and start by pulling [Austin Public Health's data](https://www.arcgis.com/home/item.html?id=08e581f856cb4ceaa56adf4493d77264&sublayer=0&view=list&sortOrder=true&sortField=defaultFSOrder#overview)---which organizes cases at the zip code level and updated frequently---to map out cases. We don't have access to where deaths occur most often, but cases at the zip code level is more than you can find in a lot of places. So we'll use what we have.

Here's where cases are occuring most often right now:

```{r mapping assets, include=FALSE}
I35 <- st_read("spatial/I35_HighwayATX.shp") %>% 
  st_transform(crs = 4326)

arterials <- st_read("spatial/arterials/CENART.shp") %>% 
  st_transform(crs = 4326) %>% 
  filter(NAME != "IH 35",
         str_detect(TYPE, "HWY|BLVD"),
         SIZE == "MAJOR")

capcog <- st_read("spatial/CAPCOG_Counties.shp") %>% 
  st_transform(crs = 4326) %>% 
  filter(COUNTY != "TRAVIS")

img <- readPNG("spatial/I35.png")

tx_zips <- tigris::zctas(state="TX",cb=TRUE) 

sf_counties <- tigris::counties(state="TX") %>% filter(GEOID=="48453")
```

```{r echo=FALSE, fig.height=4, message=FALSE, warning=FALSE, layout="l-page", paged.print=FALSE}

# For ArcGIS Data, The service ID is the key that goes after the datasets directory. Then use the 'ID' provided to pull the data into whatever format you want. For ATX, visit this site: https://services.arcgis.com/0L95CJ0VTaxqcmED/ArcGIS/rest/services/web0723/FeatureServer

atx_covid_zips_cases <- readr::read_csv("https://opendata.arcgis.com/datasets/4d913cdf3d894c3898696a7216e44180_02.csv") %>% 
  janitor::clean_names() %>% 
  dplyr::mutate(zipcode=as.character(zipcode))

atx_zips_by_cases_sf <- atx_covid_zips_cases %>%
  dplyr::left_join(tx_zips, by=c("zipcode"="GEOID10")) %>% 
  dplyr::select(zipcode, count, geometry) %>% 
  filter(count > 2) %>% 
  drop_na(count) %>% 
  sf::st_as_sf() %>% 
  st_transform(crs="ESRI:102339")

cuts <- c(0,250,500,750,1000,1250,1500,1750)

tmap_mode("plot")

tm_shape(atx_zips_by_cases_sf, bbox = sf_counties, unit = "miles") +
  tm_fill("count",title="Cases", 
          breaks =cuts, 
          fontfamily = "Graphik Regular",
          legend.hist = FALSE,
          palette = tinter("#5da5da", steps = 5)) +
tm_shape(sf_counties) +
  tm_borders(lwd = 2) +
tm_shape(I35, name = "I-35") +
  tm_lines(lwd = 3, col = "NAME", 
           palette="#d73a49", 
           title.col="Streets") +
tm_shape(arterials) +
  tm_lines(lwd = .5, col = "#9d9d9d") +
  tm_compass(type = "arrow",
             size= 1.5, bg.alpha = .6,
             color.dark = "#9d9d9d",
             position = c("right", "TOP")) +
  tm_scale_bar(color.dark = "gray60", size = .5, breaks = c(5,10),
               position = c("right", "bottom")) + 
  tm_layout(main.title = "COVID-19 Cases in Austin",
            main.title.size = 1.2,   
            main.title.fontfamily  = "Graphik Bold",
            main.title.position = c("center", "top"),
            title = " As of: Aug 13",
            title.size = 0.7,   
            title.fontfamily  = "Graphik Light",
            title.position = c("center", "top"),
            title.bg.color = "#2d2d2d",
            title.color = "white",
            fontfamily = "Graphik Regular",
            legend.outside = FALSE,
            legend.position = c("left", "bottom"),
            legend.title.fontfamily  = "Graphik Bold",
            legend.title.size = 1,
            legend.text.size = .5,
            legend.frame =  TRUE,
            legend.bg.color = "white",
            attr.outside = FALSE,
            asp = 0,
            bg.color = "transparent",
            inner.margins=c(.04,.03, .02, .01), 
            frame=FALSE) +
    tm_credits(text = "Data: Austin Public Health | Map: Matt Worthington ", 
             bg.color = "white",
             bg.alpha = NA,
             fontfamily = "Graphik Book",
             align= "right",
             position = c("RIGHT", "BOTTOM"),
             size = .4)

```

The first thing to notice is that cases are largely consolidated east of I-35. Without additional context, it's worth wondering what role an interstate plays in shielding folks on one side from Coronavirus. With additional context about how the city was intentionally segregated through a "master plan" developed in 1928 that used I-35 as a form of physical division, it's worth paying attention to the dynamics of I-35 and including it as a geographical marker throughout future analyses. 

<aside style="margin-bottom:-150px">
For those unfamiliar, I would highly recommend reading through [this analysis by the Austin Statesman](https://projects.statesman.com/news/economic-mobility/) on the role of I-35 in the city's history of racial segregation, as a starting point. Other histories have been documented elsewhere, but this is a good starting point.
</aside>

In the next few blog posts, I'll be writing about risk + resilience. Originally, I wanted to include everything here, but the charts and analysis became pretty extensive. For fear of exhausting everyone, including myself. We'll take these questions piece by piece. 

**Next Blogpost:** Who should be most worried about getting COVID?

**Note about this series:** If you're interested in asking specific questions to explore in this, reach out to me via Facebook or Twitter and I'll do my best to find data that can help provide some kind of meaningful answer.

**Where can I find the code for this blog?** Once I clean up the mess in this repo, I'll make it public on github. For now, I'm happy to share individual the Rmarkdown file used to produce each article.

<details>
<summary><strong>TLDR | </strong>Why not do this at the statewide level?</summary>
Originally, I considered focusing these articles at the statewide level for Texas, but I kept running into issues around finding data that could meaningfully answer some of my questions. The reasons for this are many, but some of the state's existing COVID-19 data cannot be aggregated at anything beyond the statewide level for reasons outside of their control. 

#### Example - Test Positivity

For example, county-level test positivity is one of those things that has been difficult because COVID-19 lab testing has largely been decentralized, with over 97% of tests being conducted in commercial labs. Consequently, this means the state has to then coordinate data from over 4 million tests conducted outside of state testing labs. 

```{r testing_gt_table, echo=FALSE, message=FALSE, warning=FALSE}

src <- "https://www.dshs.state.tx.us/coronavirus/TexasCOVID19CaseCountData.xlsx" # URL for Daily COVID Data
lcl <- basename(src)
download.file(url = src, destfile = lcl) # Downloadsthe Data

read_excel(lcl, sheet = "Tests", skip=1) %>% 
  clean_names() %>% 
  slice(1:2) %>% 
  gt() %>%
  tab_header(title = md("**Number of People Tested for SARS-CoV-2 in Texas, By Lab Type**"),
             subtitle = "Source: Texas Department of State Health Services | As of August 10th at 3:00PM CST") %>%
  tab_source_note(
    source_note = "*Unable to deduplicate figures for Commercial labs."
  ) %>% 
  tab_footnote(footnote = md("[Data: From the 'Accessible Dashboard Data' File, under the 'Tests' tab.](https://www.dshs.state.tx.us/coronavirus/additionaldata/)"), locations = cells_title("subtitle")) %>% 
    fmt_number(columns="count", suffixing=TRUE) %>% 
  cols_label(location=md("**Location**"),
             count=md("**Tests Processed**")) %>% 
  summary_rows(
    columns = vars(count),
    fns = list(
      `Total Tests` = ~sum(.)),
    formatter = fmt_number,
    decimals=0,
    use_seps = TRUE
) %>% 
  tab_options(
    grand_summary_row.background.color = "#f5f5f5",
    heading.title.font.weight = "800",
  )

```

And given that these commercial labs aren't actually part of a state agency, this means they have to learn new reporting rhythms and do work that, perhaps, they didn't plan for or know they needed to do--such as keep all of the positives and negatives for each county, record those in a database by the county of origin, deduplicate them by the person who got the test, and then share all of that information back to the state in a manner that is uniform with all the other private labs in the state. 

That said, not being able to compare how much a county is testing with how much they're testing positive weakens a potential analysis and limits how much you can explore the dynamics between risk factors and things like test positivity.

#### Example - Demographic Data

Another example of this information is demographic data about cases and fatalities. That information also doesn't exist broken down by county--sometimes due to HIPAA requirements. 

So if you wanted to analyze geographic COVID-19 trends between counties across multiple pieces of data such as demographic, known risk-factors, and other trends, you'd have a hard time accomplishing that because it currently doesn't exist.

For that reason, I've chosen to just focus on using city-level data given that cities tend to have better access to local information about their communities. 

</details>

## Photo Credit {.appendix}

<span>Photo by <a href="https://unsplash.com/@rymagsino?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Ryan Magsino</a> on <a href="https://unsplash.com/s/photos/austin-ryan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>
